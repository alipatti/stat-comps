\section{Conclusion}

In this paper, we modeled NBA basketball games as sequences of events (e.g. shots, fouls, rebounds) with the hope of creating a model that was able to predict the winner of a game while the game was in progress. Our models did learn to predict winners with 73 to 74 percent accuracy, but they were unable to significaly outperform the naive method of predicting the winner to be the team currently in the lead. To close, we discuss a few reasons why our model may have under performed and outline several directions for future work.

\subsection{Reasons for under-performance}

\subsubsection{Score accurately captures game dynamics}

There's a lot of scoring in basketball, and it's possible that there is simiply no better predictor than picking the team currently in the lead. This would be a similar outcome to performing regression on a huge number of potential explanatory variables only to discover that there's just a single variable has a statistically significant coefficient.

\subsubsection{The vanishing/exploding gradient problem}

When training our neural network, we compute the loss between the predicted win probability at time $p_t$ and the real outcome $y$. To compute the effect of an event far in the past on $p_t$, we must backpropogate through many, many recurrent units, in each one picking up an additional multiplicative term. This can lead to the gradient vanishing (when the terms are less than one) or exploding (when the terms are greater than one). The outcome is that, RNNs don't work well when events far in the past have influence on the present.

The LSTM and gated recurrent units attempt to solve this issue, but they only put a band-aid on what is really a fundamental problem of the recurrent model architecture: they can only look so far back. In recent years, a new type of model called the transformer \cite{attention-is-all-you-need} has taken the natural-language-processing and machine learning world by storm because of its non-recurrent way of modeling sequential data that does not suffer from this vanishing gradient problem.

\subsection{Future work}

\subsubsection{A different loss function}

Currently, we penalize being wrong about the game outcome the same regardless of when in the game the prediction takes place. This is easy to implement and makes sense within the framework of binary classification, but we may see better performance by weighting our loss function to priorize being right near the end of a game. We doubt that this is the source of our model's performance issues, but it's something worth considering in the future.

\subsubsection{Different sports}

It would also be interesting to see if current score continues to be the best predictor in other sports. If we think of chances to score as random events, when you sum over a large number of chances (like in basketball), one gets a lower variance estimate of the skill of a team than in a sport with fewer chances (like soccer or hockey). One might hope that our model would be able to do better in that setting.

Comprehensive play-by-play data for several thousand soccer games is available at \cite{statsbomb-open-data}, and we began preliminary cleaning and modeling in the \texttt{code} directory at \cite{stat-comps-github}. We did not have time to finish this avenue of research.

\subsubsection{A different model}

To address the vanishing gradient problem, it would interesting to see how the transformer archetecture handles sports data. In natural-language-processing, it blows recurrent networks out of the water at the cost of requiring a large ammount of training data and compute.

There is more data available if that ends up being a bottleneck: The dataset used for this project ends in 2021, and the play-by-play scraping script \cite{pbp-scraper-github} could easily be used to scrape more recent games.

\subsubsection{Feeding our network different data}

Given that our model focuses so obsessively on the current game score, it could be interesting to remove the score columns from the data fed to the network in order to force the model to learn to track the score itself in the hidden state. It's possible that this could push the network to learn a more nuanced understanding of the game. It's also possible that this could break everything.
